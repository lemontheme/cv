%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Developer CV
% LaTeX Template
% Version 1.0 (28/1/19)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Jan Vorisek (jan@vorisek.me)
% Based on a template by Jan KÃ¼ster (info@jankuester.com)
% Modified for LaTeX Templates by Vel (vel@LaTeXTemplates.com)
%
% License:
% The MIT License (see included LICENSE file)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[9pt]{developercv} % Default font size, values from 8-12pt are recommended

%----------------------------------------------------------------------------------------

% \setlength{\parskip}{0.5em}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt} % Remove header rule
\fancyfoot[L]{Adriaan Lemmens \slashsep CV}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Last modified on \today}

%---------------------------------------------------------------------------------------

% \usepackage{smartdiagram}
\usepackage{metalogo}
\usepackage{enumitem}

\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE AND CONTACT INFORMATION
%----------------------------------------------------------------------------------------

\begin{minipage}[b]{0.5\textwidth} % 45% of the page width for name
	\vspace{-\baselineskip} % Required for vertically aligning minipages
	
	% If your name is very short, use just one of the lines below
	% If your name is very long, reduce the font size or make the minipage wider and reduce the others proportionately
    \colorbox{black}{{\HUGE\textcolor{white}{\textbf{\MakeUppercase{Adriaan}}}}} % First name
	
	\colorbox{black}{{\HUGE\textcolor{white}{\textbf{\MakeUppercase{Lemmens}}}}} % Last name
	
	\vspace{10pt}
	
	{\huge NLP Engineer} % Career or current job title
\end{minipage}%
\hfill
\begin{minipage}[b]{0.3\textwidth} % 40% of the page width for the introduction text
    \vspace{-\baselineskip} % Required for vertically aligning minipages
    \begin{flushright}
        \textit{Find your metric for success,\\ and optimize for it.}
    \end{flushright}
    \vspace{18pt}
\end{minipage}%
\hfill
\begin{minipage}[b]{0.2\textwidth} % 27.5% of the page width for the first row of icons
    \begin{flushright}
    \vspace{-\baselineskip} % Required for vertically aligning minipages
	% The first parameter is the FontAwesome icon name, the second is the box size and the third is the text
	% Other icons can be found by referring to fontawesome.pdf (supplied with the template) and using the word after \fa in the command for the icon you want
    \begin{tikzpicture}
        \node[circle, draw=black, line width=1.5mm, inner sep=1cm, fill overzoom image=./lemontheme] () {};
    \end{tikzpicture}
    \end{flushright}
\end{minipage}

%----------------------------------------------------------------------------------------
%	INTRODUCTION, SKILLS AND TECHNOLOGIES
%----------------------------------------------------------------------------------------
\vspace{1em}

\begin{minipage}[]{\textwidth}
    \icon{MapMarker}{12}{\href{https://osm.org/go/0EozeLT5--}{Leuven 3001, Belgium}}%
    \slashsep\icon{At}{12}{\href{mailto:adriaan.jm.lemmens@gmail.com}{adriaan.jm.lemmens@gmail.com}}%
    \slashsep\icon{Phone}{12}{\href{tel:+32-472-69-03-80}{+32 472 69 03 80}}%
    \slashsep\icon{BabyCarriage}{12}{1992}
    
    \vspace{-0.5em}\icon{Github}{12}{\href{https://github.com/lemontheme/}{lemontheme}}
    \slashsep\icon{LinkedinIn}{12}{\href{https://www.linkedin.com/in/adriaan-lemmens/}{adriaan-lemmens}} 
\end{minipage}

\cvsect{About Me}

I'm a linguist-turned-programmer with over \textbf{two years} of experience
applying \textbf{Natural Language Processing} (NLP) methods to a wide
array of real-world challenges in \textbf{diverse domains}. I'm used to
delivering production-ready solutions that combine \textbf{machine learning},
old-school tricks, and a healthy dose of pragmatism. I <3 \textbf{Python}, but also
enjoy learning new programming languages. In my free time, when I'm
not reading up on the field, I'm usually carrying out toy experiments, 
working on pet projects, or making modest contributions to open-source
libraries.


%-------------------------------------------------------------------------------
%	EXPERIENCE
%-------------------------------------------------------------------------------

\cvsect{Experience}

% $\stackrel{\mathrm{promoted}}{\longrightarrow}$
\begin{entrylist}
	\entry
		{2017 -- Aug. 2019}
        {Computational Linguist $\longrightarrow$  NLP Engineer}
        {\href{http://nlp.town}{NLP Town}}
        {Developed tailor-made solutions (software and models) for clients in
         various industries/domains, such as E-commerce, Translation, GovTech, Media,
         Health, Education, and Legal. On average, projects ranged from one to eight 
         months in duration, sometimes involving on-site consulting on my part. In January
         2019, I was promoted to NLP Engineer to reflect the fact that my
         responsibilities had evolved to cover most levels of the development stack.}

	\entry
		{Spring 2017}
		{MAI SLT Intern}
        {\href{http://nlp.town}{NLP Town}}
        {Prototyped a content-driven recommender engine for eBooks, using genre,
         emotion, and topic assignment predictions + clever document segmentation
         strategies.}
         % \texttt{SVM}\slashsep\texttt{LDA}\slashsep\texttt{Dynamic Programming}\slashsep\texttt{Ranking}\slashsep\texttt{scikit-learn}\slashsep\texttt{gensim}}
\end{entrylist}

\vspace{-1em}

%----------------------------------------------------------------------------------------
%	EDUCATION
%----------------------------------------------------------------------------------------

\cvsect{Education}

\begin{entrylist}
	\entry
		{2016 -- 2017}
        {MSc. Artificial Intelligence (MAI)}
		{KU Leuven}
        {Program: Speech \& Language Technology (SLT).\\
         Relevant subjects: Natural Language Processing, Machine Learning, 
         Speech Recognition, Text-based Information Retrieval, Language Engineering Applications.\\
         Internship: see \textsc{experience}.}
	\entry
		{2015 -- 2016}
        {MA Linguistics}
		{KU Leuven}
        {Program: Formal \& Computational Linguistics.\\
         Thesis title: Pictograph-to-text translation with \textit{Depicto}, a formal grammar-based
         translation system for use in assistive writing applications.}
	\entry
		{2011 -- 2015}
        {BA Languages \& Literature}
        {KU Leuven}
        {Specialization: Synchronic linguistics.\\
         Discovered the joy of programming thanks to an introductory elective on 
         Computational Linguistics. Began teaching myself R, Perl, and Python, and taking an
         interest in statistical methods.}
    \entry
        {2006 -- 2010}
        {IGCSEs \& International Baccalaureate}
        {British International School of Shanghai, Pudong}
        {}
\end{entrylist}

\vspace{-2em}

%----------------------------------------------------------------------------------------
%	ADDITIONAL INFORMATION
%----------------------------------------------------------------------------------------
\cvsect{Skills}

\textbf{Python} -- Upwards of 30K SLOC$^*$, split across exploratory notebooks,
data and training pipelines, pet projects, distributed web services, and many
things in between; up-to-date with new language features and with the state of
the library ecosystem; comfortable writing tests as well as profiling and
debugging; huge fan of type annotations; familiar with available tools for
optimized numeric computation; currently learning Cython. ($* \leftarrow$
`source lines of code' is a questionable metric, but it gives an
indication.)\\

\textbf{Natural Language Processing} -- Experienced building NLP-based services
for use in real-world applications. At one point or other, I have implemented
tailor-made and/or benchmarked off-the-shelf solutions to most well-known NLP
tasks, such as classification, sequence labeling, word/document representation
learning, information extraction, parsing, extractive summarization, text
simplification, machine translation, automatic post-editing, topic modeling,
document similarity, clustering, keyword extraction, question answering,
coreference resolution, and conversational agents. I'm well-versed in
bootstrapping data for domain-specific learning tasks. Most of the projects
I've worked on involved a combination of English, Dutch, French, and German.\\ 

\textbf{Machine Learning} -- Working knowledge of major learning algorithms,
including their inductive biases. Practical experience with both classic
(`shallow') methods and deep learning; however, due to data and project time
constraints in current role, I've spent more time employing the former. Very
productive with scikit-learn API, but also familiar with Keras API. Another
goal for 2019: Getting better acquainted with PyTorch and implementing more
experimental model architectures.  Two of my pet interests are research
reproducibility and model deployment.\\

\textbf{Search \& Analytics} -- Retrieving relevant information from large
document collections is one of my favorite applications of NLP. For use cases
with strict runtime \& stability requirements, my go-to tool is the
Elasticsearch engine. For more experimental use cases, where flexibility trumps
performance guarantees, I've also built my own search engines. One of my goals
for 2019 is to explore the possibility of using PyLucene as a means to bridge
the performance gap with the Lucene--Solr--Elasticsearch trinity while allowing
for richer, semantic-based document representations and custom relevance
functions implemented in pure Python.\\

\textbf{Software development \& architecture} -- I've designed numerous NLP
applications from the ground up, applying Lean principles in order to deliver
quickly and to deal efficiently with changing requirements. In terms of
architectural style, I enjoy borrowing ideas from the higher-level paradigms of
both OOP and Functional Programming. With respect to NLP in particular, I'm
always on the lookout for elegant abstractions, regulary drawing
inspiration from the source code of open-source libraries.\\

\textbf{Linguistic intuition} -- Formal training in linguistic analysis. Over
the years, this has proven useful for creative feature engineering, forming
hypotheses about model architectures, adapting pipelines to new languages, and
evaluating a dataset for possible biases that do not hold in the domain where
trained models will ultimately be used.\\

\textbf{Other}
\begin{itemize}[leftmargin=*]
    \setlength\itemsep{-2pt}

\item \textbf{Containerization} with Docker -- Extensive experience (going on
    two years of enthusiastic usage). Aware of best practices (and pitfalls)
    for writing Dockerfiles and Docker Compose recipes. 

\item \textbf{The Unix toolkit} -- I know my way around GNU/Linux and macOS
    (being a dekstop user of both). Through both, I have learned to appreciate
    the wealth of preinstalled \textit{Unixy} utilities when building data
    pipelines or when invoking functionality that isn't easily optimized in
    Python.

\item \textbf{Mentoring} -- Onboarding developers at client companies; hosting
    workshops; helping interns get started and reviewing their code; 1-on-1
    Python tutoring.

\item \textbf{Other langs} (From 'proficient' to `I own at least one book but 
    am out of practice') -- Regex, Bash \& Fish, Java, SQL, Make, Clojure,
    Go, C, Prolog, Perl, R, Elm, Nim.
\end{itemize}

\cvsect{Open Source}
\vspace{-1em}
\begin{itemize}[leftmargin=*]
    \setlength\itemsep{-2pt}
    \item Improved \textbf{spaCy}'s preprocessing functionality for Dutch
        on multiple fronts, including lemmatization.
    \item On the roadmoap: Open-sourcing \textbf{trefwurd} \& \textbf{wurdbits} 
        -- Python libraries for
        lemmatization and byte-pair encoding, respectively, which grew out of
        an intellectual exercise to to improve spaCy's lemmatization without
        resorting to statistical/neural methods.
\end{itemize}


%----------------------------------------------------------------------------------------

\end{document}
